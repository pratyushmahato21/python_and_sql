# connecting Python to Postgresql.

Step 1: we create a database in SQL

Step 2: Read data in pandas 

Step 3: Clean the data & perform EDA

Step 4: Create a connection between jupyter notebook & SQL database

Step 5: Create tables for SQL database in Python as per ER Model & Data Model & commit them

Step 6: Bulk insert the final cleaned dataframes into various tables using the io module & string object

# note: refer to the jupyter notebook, where 'order_products' is inserted. 'order_products' is a large dataset size > 500 MB.
# Always use this method for data insertion. It's fast & computationally less expensive. Refer to the code in the jupyter notebook attached

dataset link: https://www.kaggle.com/competitions/instacart-market-basket-analysis
